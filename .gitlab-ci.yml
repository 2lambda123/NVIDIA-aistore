image: aistore/ci:1.15

stages:
  - build
  - test-short
  - test-long

variables:
  AIS_NODE_FLAGS: "-skip_startup"
  MODE: debug # run tests with debug asserts
  NUM_TARGET: 5
  NUM_PROXY: 5
  FS_CNT: 4


# Templates

.gather_logs_template: &gather_logs_def
  after_script:
    - make kill # To make sure that nodes flushed the logs.
    - mkdir $CI_PROJECT_DIR/logs
    - find /tmp/ais -type f -name "*log*" -exec cp {} $CI_PROJECT_DIR/logs/ \;
  artifacts:
    when: on_failure
    paths: [ logs/ ]
    expire_in: 1 days

.default_only_template: &default_only_def
  only:
    - master
    - merge_requests
    - schedules

.test_long_template: &test_long_def
  stage: test-long
  tags:
    - ais
  timeout: 2h30m
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
  <<: *gather_logs_def

# Stages

build:linux:
  stage: build
  tags:
    - ais
  timeout: 5m
  <<: *default_only_def
  script:
    - AIS_CLD_PROVIDERS="ais aws azure gcp hdfs" make node
    - AIS_CLD_PROVIDERS="" MODE="" make node # build one node without debug assert (to see if it compiles)
    - make authn
    - make aisfs
    - make cli
    - make aisloader

lint:linux:
  stage: build
  tags:
    - ais
  timeout: 5m
  <<: *default_only_def
  script:
    - make lint
    - make fmt-check
    - make spell-check

test:short:
  stage: test-short
  tags:
    - ais
  timeout: 16m
  <<: *default_only_def
  except:
    variables:
      - $CI_MERGE_REQUEST_LABELS =~ /.*skip-ci.*/
  script:
    - make aisfs cli aisloader
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo n; echo n; echo n; echo n; echo n; })
    - DEPLOY_AS_NEXT_TIER="true" make deploy <<< $'1\n1\n3\nn\nn\nn\nn\nn\n'
    - ais attach remote alias=http://127.0.0.1:11080 # attach to remote cluster
    - BUCKET="test" make test-short
    - FLAGS="--duration=10s" make test-aisloader
  <<: *gather_logs_def

test:authn:
  stage: test-short
  tags:
    - ais
  timeout: 20m
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
  variables:
    AUTH_ENABLED: "true"
    AUTHN_URL: "http://localhost:52001"
    AUTHN_SU_NAME: "admin"
    AUTHN_SU_PASS: "admin"
  script:
    - make cli
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo n; echo n; echo n; echo n; echo n; })
    - ais auth login $AUTHN_SU_NAME -p $AUTHN_SU_PASS
    - BUCKET="test" RE="TestAuth" make test-run
    - ais auth logout

test:https:
  stage: test-short
  tags:
    - ais
  timeout: 20m
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
  variables:
    AIS_ENDPOINT: "https://localhost:8080"
    AIS_USE_HTTPS: "true"
    AIS_SERVER_CRT: "$CI_PROJECT_DIR/localhost.crt"
    AIS_SERVER_KEY: "$CI_PROJECT_DIR/localhost.key"
    AIS_SKIP_VERIFY_CRT: "true"
    BUCKET: "test"
  script:
    - openssl req -x509 -out $AIS_SERVER_CRT -keyout $AIS_SERVER_KEY -newkey rsa:2048 -nodes -sha256 -subj '/CN=localhost' -extensions EXT -config <( printf "[dn]\nCN=localhost\n[req]\ndistinguished_name = dn\n[EXT]\nsubjectAltName=DNS:localhost\nkeyUsage=digitalSignature\nextendedKeyUsage=serverAuth")
    - make aisfs cli
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo n; echo n; echo n; echo n; echo n; })
    - DEPLOY_AS_NEXT_TIER="true" make deploy <<< $'1\n1\n3\nn\nn\nn\nn\nn\n'
    - sleep 3
    - ais attach remote alias=https://127.0.0.1:11080 # attach to remote cluster
    - make test-short

test:long:
  <<: *test_long_def
  variables:
    NUM_PROXY: 6
    BUCKET: "test"
  script:
    - make cli
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo n; echo n; echo n; echo n; echo n; })
    - make test-long

test:cloud:aws:
  <<: *test_long_def
  variables:
    NUM_PROXY: 6
    BUCKET: "aws://ais-ci"
    AWS_REGION: "us-east-2"
  script:
    - make cli
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo y; echo n; echo n; echo n; echo n; })
    - make test-long

test:cloud:gcp:
  <<: *test_long_def
  variables:
    NUM_PROXY: 6
    BUCKET: "gs://ais-ci"
    GOOGLE_APPLICATION_CREDENTIALS: "/tmp/gcs.json"
  script:
    - make cli
    - echo "${GOOGLE_APPLICATION_CREDENTIALS_JSON}" > "${GOOGLE_APPLICATION_CREDENTIALS}"
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo n; echo y; echo n; echo n; echo n; })
    - make test-long

test:soak:
  stage: test-long
  tags:
    - ais
  timeout: 10m
  only:
    - schedules
  script:
    - make aisloader
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo n; echo n; echo n; echo n; echo n; })
    - FLAGS="--short --rec-cycles=1" make test-soak

test:aisloader:
  stage: test-long
  tags:
    - ais
  timeout: 10m
  only:
    - schedules
  script:
    - make aisloader
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo n; echo n; echo n; echo n; echo n; })
    - sleep 10 # make sure that cluster properly starts
    - FLAGS="--duration=5m" make test-aisloader

# TODO: The job is for now disabled because it gets stuck on memsys benchmarks.
#test:bench:
#  stage: test-long
#  tags:
#    - ais
#  only:
#    - schedules
#  script:
#    - go get -u golang.org/x/tools/cmd/benchcmp
#    - make test-bench


# Kubernetes stages

.test_kube_template: &test_kube_def
  tags:
    - ais-kube
  timeout: 30m
  variables:
    NUM_TARGET: 1
    NUM_PROXY: 1
    BUCKET: "gs://ais-ci-kube"
    GOOGLE_APPLICATION_CREDENTIALS: "/tmp/gcs.json"
  before_script:
    - kubectl delete pods,services -l nvidia.com/ais-etl-name # TODO: this can be removed once the lifecycle of transformers is implemented.

test:kube-short:
  stage: test-short
  <<: *test_kube_def
  only:
    - merge_requests
  except:
    variables:
      - $CI_MERGE_REQUEST_LABELS =~ /.*skip-ci.*/
  script:
    - export NUM_TARGET=3
    - MINIKUBE_TESTING="1" make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo y; echo n; echo n; echo n; echo n; })
    - status=0
    - RE="TestETL" make test-short || status=$?
    - make kill
    - exit $status # TODO: hack to prevent pod hangs on failures

test:kube:
  stage: test-long
  <<: *test_kube_def
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_MERGE_REQUEST_LABELS =~ /.*kube-ci.*/' # Add more labels if needed in the future
  script:
    - export NUM_TARGET=3
    - MINIKUBE_TESTING="1" make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo y; echo n; echo n; echo n; echo n; })
    - status=0
    - RE="TestETL" make test-run || status=$?
    - make kill
    - exit $status # TODO: hack to prevent pod hangs on failures

test:kube-single-target:
  stage: test-long
  <<: *test_kube_def
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_MERGE_REQUEST_LABELS =~ /.*kube-ci.*/' # Add more labels if needed in the future
  script:
    #  Do not set MINIKUBE_TESTING as we want to have a tests checking correctness with non-testing environment.
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo y; echo n; echo n; echo n; echo n; })
    - status=0
    - RE="TestETL" make test-run || status=$?
    - make kill
    - exit $status # TODO: hack to prevent pod hangs on failures

test:kube-aisloader:
  stage: test-long
  <<: *test_kube_def
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: manual
      allow_failure: true
    - if: '$CI_PIPELINE_SOURCE == "schedule"'
    - if: '$CI_MERGE_REQUEST_LABELS =~ /.*kube-ci.*/' # Add more labels if needed in the future
  script:
    - make aisloader
    - make deploy <<< $({ echo $NUM_TARGET; echo $NUM_PROXY; echo $FS_CNT; echo n; echo n; echo n; echo n; echo n; })
    - sleep 10 # Give some time for the cluster to stabilize.
    - status=0
    - BUCKET="test" FLAGS="--duration=2m --etl" make test-aisloader || status=$?
    - make kill
    - exit $status # TODO: hack to prevent pod hangs on failures
